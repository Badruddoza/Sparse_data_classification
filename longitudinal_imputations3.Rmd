---
title: "Classification in Sparse and Irregular Samples: \n Evidence from Malignancy Detection"
author: 
- "Syed Badruddoza"
- "Yuan Wang"
date: "`r format(Sys.time(), '%d %B %Y')`"
tags: [Classification, Gaussian]
abstract: |
  This article compares the predictability of various classifiers using adrenal tumor data that have temporal sparsity. Classifiers include Generalized Linear Model (GLM), Kernel, nonparametric, K Nearest Neighbors, Neural Networks, Random Forests, and eXtreme Gradient Boosting. We assume that the underlying processes are Gaussian, and interpolate the missing observations connecting the observed points using various methods of longitudinal data imputation. Prediction performances were evaluated in terms of sensitivity, specificity, accuracy, and Cohen's Kappa. Results show that Random Forests and K Nearest Neighbors are powerful predictors and generally perform better in identifying malignang cells. Our analysis also suggests that naive linear imputations can be falsely make GLM perform better than other methods. 
output: pdf_document
---

## Introduction

Classification of Gaussian processes (GPs) and sparse approximation both are widely reviewed in the literature, with very few overlaps of the two (Hensman et al. 2015). The literature on functional data classification mainly take regression-based, density-based, or machine learning approach.  Regression-based approaches maximize the likelihood and quasi-likelihood under frequentist or Bayesian setting (e.g., James 2002; Muller and Stadmuller 2005; Zhu et al. 2010; Wang et al. 2018). The density-based approach assumes underlying density and assign the class according to the estimated density via EM algorithm (James and Hastie 2001; Zhu et al. 2012). Researchers have also applied machine learning methods that minimize intra-group distance and maximize inter-group distance for classification, such as k nearest neighborhood and support vector machine (Ferraty and Vieu 2003; Li and Yu 2008).

Several practices appear in the literature in classifying sparse or low rank Gaussian processes under regression setting (Quinonero-Candela and Rasmussen 2005). These studies often use a series of optimally chosen inducing points (e.g., Titsias 2009; Hensman et al. 2013). However, placing the inducing input points are difficult, and scalability of the method is constrained by time and complexity (Hensman et al. 2015).

The current study undertakes a simple approach in classification of the sparse and irregular samples. It uses a temporally sparse longitudinal data of adrenal tumor scans where a lesion can be cancerous (malignant) or noncancerous (benign), and applies a number of imputation methods to  replace the missing values with some combination of observed data points. Finally, it utilizes several satistical and machine learning methods classi and then compares among the classification performances of different methods.

## Data

The data come from a liver cancer study between 2007 and 2009 on 16 patients with verified neuroendocrine liver metastases, where patients underwent a dynamic perfusion computed tomography (CT) protocol. Perfusion characteristics in CT acts as a quantitative basis for cancer detection, prognostication, and treatment monitoring. We use CT data of 378 lesions containing malignant tissues or normal tissues. Each patient participated in two phased CT acquisition spanning 10 minutes. Phase 1 includes cine acquisition during a breath-hold, followed by Phase 2 of eight intermittent short breath-hold helical scans. 

The objective of this study is to evaluate the performance of different classifier models in distinguishing tumor lesions from normal liver lesions. The sparse nature of the data originates from the availability and frequency of scans. Number of times lesions were scanned varies from one to six. The intervals between two scan time is not equal for each lesion. The following table shows the summary statistics of the variables. The predicted variable "mal" takes 1 if the cell is malignant, zero otherwise. The lesions are identified by "id". Time of scan is indexed from -200 onwards where -200 indicates the point of the benchmark scan, and 0 indicates the point of perfusion. The time index sparsely varies from -200 to 1155. 


```{r, include=FALSE, echo=FALSE, warning=FALSE}

#install.packages("longitudinalData")
rm(list=ls())
set.seed(123)
setwd("E:/2. Other research/1. Classification of Gaussian Process/actual data")
#install.packages("dplyr")
require(dplyr);require(longitudinalData);require(tidyverse);require(tidyr);
require(ggplot2);require(fda.usc);library(knitr);library(kableExtra);library(caret)
#install.packages("magick");#install.packages("webshot");#webshot::install_phantomjs()
#install.packages('processx')

################################################################# load data set
dat=readRDS("Adrenal-EMRE-dynamic.RDS")
#separate out the working data and rename variables
dat0<-cbind.data.frame(mal=as.integer(dat$malignancy),
                       id=as.factor(dat$lesionID),
                       time=as.integer(dat$time),
                       mean=as.numeric(dat$calc_mean))

################################################################# summary statistics
dat_sum<-rbind.data.frame(cbind("Malignancy","Dummy variable",round(mean(dat0$mal),3),round(sd(dat0$mal)),round(min(dat0$mal),3),round(max(dat0$mal),3)),
  cbind("Mean index","Numeric",round(mean(dat0$mean),3),round(sd(dat0$mean),3),round(min(dat0$mean),3),round(max(dat0$mean),3)),
  cbind("Time of scan","Integer",round(mean(dat0$time),3),round(sd(dat0$time),3),min(dat0$time),max(dat0$time)),
  cbind("Patient ID","Character","Count=",length(unique(dat0$id)),"Sample=",dim(dat0)[1]))
colnames(dat_sum)<-c("Variable","Type","Mean","SD","Min","Max")

```


Summary statistics



```{r, echo=FALSE, warning=FALSE, results='asis'}
kable(dat_sum, caption="Summary Statistics", booktabs=T) 
#%>%
#  kable_styling(latex_options = c("striped", "hold_position"))
```


Plotting of the actual data



```{r, echo=FALSE, warning=FALSE, results='asis'}
#plot the data set
ggplot(data=dat0,aes(x=time,y=mean,color=as.factor(mal)))+
  geom_point()+
  geom_line(aes(group=id), alpha = 0.2)+
  ggtitle("Figure 1: Scan results over time")+
  xlab("Time of scan")+
  ylab("Mean Index")+
  labs(color="Malignancy")+
  theme_bw()

```


## Dealing with missing values

There are several ways to deal with the missing values. We use a combination of methods. Using "zoo" package (Zeileis et al. 2019), we replace the missing values using row (lesion) means. For each point of time, a missing observation takes the average of two neighboring values that are observed on its right and left. The process generates connecting lines between two observed points, as shown in the figure below. Lesions with only one observed value spreads the value over the entire timespan, thus forms a straight line.


Different imputation methods using the package "longitudinalData"

```{r, include=FALSE, echo=FALSE, warning=FALSE}
################################################################# split into training and testing sample
dat1<-spread(dat0,time,mean)
dat1<-dat1 %>% dplyr::select(id,names(dat1)[which(names(dat1)!="id")]) # make id the first variable
trainIndex<-sample(seq_len(dim(dat1)[1]),size=floor(0.9*nrow(dat1)))

```

## Analysis

We utilize a number of observed classifying methods, namely, Generalized Linear Model (GLM), Kernel, K Nearest Neighbors (KNN), non-parametric, Neural Networks (NN), and Random Forests (RF). The former four methods come from "fda.usc" package (Bande et al. 2019), and the latter two come from "caret" package (Kuhn et al. 2019). GLM assumes binomial family with equal weights on each observation. Kernel and nonparametric methods use normal kernels. Random Forests uses ranger method with number of randomly selected predictors equals to the sqare root of total number of predictors. Neural network has logistic output units with zero weight decay.

The following table compares the all methods in terms of their success in identifying non-malignant cells as non-malignant, and malignant cells as malignant. Interestingly, the probability of correct identification is not consistent for a given method. For example, GLM performs the best in identifiying non-malignant, but not in identifying malignant cells. Kernel and nonparametric predict malignant cells better than GLM. Compared to the rest of the methods, GLM's prediction rates change less by the probabilities because we assumed some linear connection between two observed points. Machine learning models can identify non-malignant moderately well but do not appear powerful in predicting the malignant cells.


## References

Bande, M., de la Fuente, M., Galeano, P., Nieto, A., and Garcia-Portugues, E., 2019. Package fda.usc: Functional Data Analysis and Utilities for Statistical Computing. Available on cran.r-project.org. Version 2.0.0 November 14.

Ferraty, F. and Vieu, P., 2003. Curves discrimination: a nonparametric functional approach. Computational Statistics and Data Analysis, 44(1-2), pp.161-173.

Hensman, J., Fusi, N., and Lawrence, N.D. 2013. Gaussian processes for big data. In Nicholson, A. and Smyth, P., editors, Uncertainty in Artificial Intelligence, volume 29. AUAI Press.

Hensman, J., Matthews, A. and Ghahramani, Z., 2015. Scalable variational Gaussian process classification. Appearing in Proceedings of the 18th International Conference on Artificial Intelligence and Statistics (AISTATS)
2015, San Diego, CA, USA. JMLR: W&CP volume 38.

James, G. M. 2002. Generalized linear models with functional predictors. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 64(3), 411-432.

James, G. M., & Hastie, T. J. 2001. Functional linear discriminant analysis for irregularly sampled curves. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 63(3), 533-550.

Kuhn, M., Wing, J., Weston, S., et al. 2019. Miscellaneous Functions for Training and Plotting Classification and Regression Models. Available on cran.r-project.org. Version 6.0-84 April 27.

Li, B. and Yu, Q., 2008. Classification of functional data: A segmentation approach. Computational Statistics & Data Analysis, 52(10), pp.4790-4800.

Müller, H. G., and Stadtmüller, U. 2005. Generalized functional linear models. the Annals of Statistics, 33(2), 774-805.

Quiñonero-Candela, J. and Rasmussen, C.E., 2005. A unifying view of sparse approximate Gaussian process regression. Journal of Machine Learning Research, 6(Dec), pp.1939-1959.

Titsias, M., 2009, April. Variational learning of inducing variables in sparse Gaussian processes. In Artificial Intelligence and Statistics, pp. 567-574.

Wang, Y., Hu, J., and Hobbs, B., 2018. Multivariate Functional Classifiers of Hepatic Metastases Integrating Scans and Biomarkers from Perfusion CT. Statistical Methods in Medical Research. pp.2-21.

Zeileis, A., Grothendieck, G. Ryan, J. Ulrich, J., et al. 2019. S3 Infrastructure for Regular and Irregular Time Series (Z's
Ordered Observations). Available on cran.r-project.org. Version 1.8-6 May 28.

Zhu, H., Brown, P. J., & Morris, J. S. 2011. Robust, adaptive functional regression in functional mixed model framework. Journal of the American Statistical Association, 106(495), 1167-1179.






```{r, echo=FALSE, warning=FALSE, results='asis'}

########################################################## THE LONG LOOP ##################################
i=1
#method_list<-c("linearInterpol.locf", "linearInterpol.local", "linearInterpol.bisector", 
#               "trajMean", "trajMedian", "trajHotDeck", "locf", "nocb", 
#               "copyMean.locf", "copyMean.local", "copyMean.bisector")
method_list<-c("linearInterpol.locf", "linearInterpol.local")

#simplest_method_list<-c("crossMean", "crossMedian", "crossHotDeck")
#not_running<-c("linearInterpol.global","copyMean.global")
# locf=last observation carried forward, nocb=next observation carried before

for(j in method_list){
  
#print(paste0("Starting method ",j," at ",Sys.time()))
  
keep<-c("dat0","dat1","trainIndex","i","j")
rm(list=ls()[!ls() %in% keep])

dat1_train<-dat1[trainIndex,];dat1_test<-dat1[-trainIndex,]
dat1_train_m<-dat1_train[dat1_train$mal==1,];dat1_train_b<-dat1_train[dat1_train$mal==0,]
dat1_test_n<-dat1_test %>% mutate(mal=NA) # make the response of test data missing
dat1_m<-rbind(dat1_train_m,dat1_test_n);dat1_b<-rbind(dat1_train_b,dat1_test_n)

################################################################# imputation
dat1_m[,2:dim(dat1_m)[2]]<-imputation(as.matrix(dat1_m[,2:dim(dat1_m)[2]]),j)
dat1_b[,2:dim(dat1_b)[2]]<-imputation(as.matrix(dat1_b[,2:dim(dat1_b)[2]]),j)

################################################################# imputation performance by malignant and benign sample in test data
# first identify which part of the sample was test
dat1_m_i<-dat1_m[which(dat1_m$id %in% dat1_test$id),];dat1_b_i<-dat1_b[which(dat1_b$id %in% dat1_test$id),]
# make the response missing because it got imputed meanwhile
dat1_m_i<-dat1_m_i %>% mutate(mal=NA);dat1_b_i<-dat1_b_i %>% mutate(mal=NA)
# count nonmissing columns in each low
dat1_test1<-dat1_test %>% mutate(rs=dim(dat1_test)[2]-2-rowSums(is.na(dat1_test[,3:dim(dat1_test)[2]])))
adat<-bind_rows(cbind(dat1_m_i,m="Malignant" ),
                cbind(dat1_b_i,m="Benign"),
                cbind(dat1_test,m="Actual"))
# make the data long for graphs
adat1<-gather(adat,"time","mean",3:(dim(adat)[2]-1));
adat1<-adat1 %>% arrange(m,id,time)
adat2<-spread(adat1,"m","mean")
adat2<-adat2 %>% arrange(id,time) %>%
  group_by(id,time) %>%
  summarize_at(c("mal","Actual","Benign","Malignant"),mean,na.rm=TRUE)
adat2$Actual[is.nan(adat2$Actual)==TRUE]<-NA  #replace Nan with NA

########### Plotting selected points to see the performance of imputation
# keep only 3 lesions with 1,2, and 3 observations
shortlist<-dat1_test1 %>% filter(rs<=3) %>%  dplyr::select(id,rs) %>%  
  arrange(rs) %>%  mutate(rs1=ifelse(rs!=lag(rs),1,0)) %>%
  mutate(rs1=ifelse(is.na(rs1)==TRUE,1,rs1)) %>%  filter(rs1==1)
gdat<-adat2 %>% filter(id %in% shortlist$id) %>%
  rename(Benign_based=Benign) %>%
  rename(Malignant_based=Malignant)
gdat<-gather(gdat,"Imputation","mean",4:(dim(gdat)[2]))
gr<-ggplot()+
  geom_line(data=gdat[gdat$Imputation!="Actual",], aes( as.numeric(time),as.numeric(mean),group=id,color=Imputation),lwd=1)+
  geom_point(data=gdat[gdat$Imputation=="Actual",],aes(as.numeric(time),as.numeric(mean),shape=as.factor(mal)),size=3)+
  labs(title=paste0("Figure ",i+1,": Imputed by ",j),x="Time of scan", y="Mean index")+theme_bw()+
  theme(plot.title=element_text(size=12))+
  scale_shape(name="Malignancy")

cat('\n')

print(gr)

cat('\n')

#}
#```



#```{r,include=FALSE,echo=FALSE,eval=FALSE,warning=FALSE}

############################# choosing the best method
if(sum((adat2$Actual-adat2$Benign)^2,na.rm=TRUE)>=sum((adat2$Actual-adat2$Malignant)^2,na.rm=TRUE)){
  #print("Malignant performs better")
  data<-merge(dat1_m,dat1_b[which(dat1_b$id %in% dat1_train_b$id)],all=TRUE)
  }else{
    #print("Benign performs better")
    data<-merge(dat1_b,dat1_m[which(dat1_m$id %in% dat1_train_m$id)],all=TRUE)
    }
data<-data %>% mutate(test=ifelse(mal!=0 & mal!=1,1,0)) %>% 
  dplyr::select(test,names(data)[which(names(data)!="test")]) %>% arrange(test,id)
data[,3:dim(data)[2]]<-imputation(as.matrix(data[,3:dim(data)[2]]),j)
data$mal[data$test==1]<-NA
data$mal<-as.factor(data$mal)

######################################################### Analysis
data_train<-data %>% filter(test==0) 
data_test<-data %>% filter(test==1)

#using LongitudinalData package
mdata1<-data_train[,4:dim(data_train)[2]]
mlearn1=fdata(mdata1)
glearn=data_train$mal
dataf<-data.frame(glearn) 
data_train_l=list("df"=dataf,"x"=mlearn1)

out.glm=classif.glm(glearn~x, data = data_train_l)
out.np=classif.np(glearn,mlearn1)
out.knn=classif.knn(glearn,mlearn1,knn=c(3,5,7))
out.kernel=classif.kernel(glearn,mlearn1)

mdata2<-data_test[,4:dim(data_test)[2]]
mlearn2=fdata(mdata2)
data_test_l<-list("x"=mlearn2)

glm1<-predict.classif(out.glm,data_test_l)
np1<-predict.classif(out.np,mlearn2)
knn1<-predict.classif(out.knn,mlearn2)
kernel1<-predict.classif(out.kernel,mlearn2)
#print("LongitudinalData completed")

#using machine learning
#neural network
nn<-train(x=mdata1,y=data_train$mal,method="nnet",trace=FALSE)
nn1<-predict(nn,mdata2)

#random forests
rf<-train(x=mdata1,y=data_train$mal,method="ranger")
rf1<-predict(rf,mdata2)

#extreme gradient boosting
gb<-train(x=mdata1,y=data_train$mal,method="xgbTree")
gb1<-predict(gb,mdata2)
#print("Machine Learning completed")


#collect predictions
predicted<-merge(dat1_test,cbind.data.frame(id=data_test$id,
                                            GLM=glm1,
                                            NP=np1,
                                            KNN=knn1,
                                            Kernel=kernel1,
                                            NNet=nn1,
                                            RF=rf1,
                                            XGB=gb1),all=TRUE)
methods<-colnames(predicted)[(names(predicted) %in% names(data_test))==FALSE]
predicted1<-predicted %>% dplyr::select(mal,methods)
predicted1<-predicted1 %>% mutate_all(as.character)

# overall performance
reslist0<-c()
for(v in names(predicted1)[-which(names(predicted1)=="mal")]){
  predicted2<-predicted1 %>% dplyr::select(mal,v)
  tt<-table(predicted2)
  a=0;d=0;c=0;b=0
  tryCatch({a<-tt[2,2]}, error=function(e){});
  tryCatch({b<-tt[1,2]}, error=function(e){});
  tryCatch({c<-tt[2,1]}, error=function(e){});
  tryCatch({d<-tt[1,1]}, error=function(e){});
  tn<-d/(sum(tt));tp<-a/(sum(tt));fp<-b/sum(tt);fn<-c/sum(tt)
  tpr<-tp/(tp+fn);tnr=tn/(tn+fp);acc<-(tp+tn)/(tp+tn+fp+fn);
  nn=(a+b+c+d);po=(a+d)/nn;py=((a+b)/nn)*((a+c)/nn);pn=((c+d)/nn)*((b+d)/nn)
  pe=py+pn;kappa=(po-pe)/(1-pe);
  reslist0<-c(reslist0,v,round(tpr,4),round(tnr,4),round(acc,4),round(kappa,4) )
}
reslist1<-data.frame(matrix(c(reslist0),nrow=length(methods),byrow=TRUE)) %>%
  arrange(-as.numeric(X5)) %>% mutate(Scan="Overall") %>%
  rename(Model=X1) %>% rename(TPR=X2) %>% rename(TNR=X3) %>% rename(Accuracy=X4) %>% rename(Kappa=X5)
#reslist1

# performance with one multiple scans only
tvars<-colnames(predicted)[(names(predicted) %in% names(data_test))==TRUE]
tvars<-tvars[-c(1,2)]
predicted3<-predicted %>%
  mutate(Scan=dim(predicted[,tvars])[2]-rowSums(is.na(predicted[,tvars]))) %>%
  dplyr::select(mal,methods,Scan) %>%
  filter(Scan>1) %>% dplyr::select(-Scan)
predicted3<-predicted3 %>% mutate_all(as.character)

reslist0<-c()
for(v in names(predicted3)[-which(names(predicted3)=="mal")]){
  predicted4<-predicted3 %>% dplyr::select(mal,v)
  tt<-table(predicted4)
  a=0;d=0;c=0;b=0
  tryCatch({a<-tt[2,2]}, error=function(e){});
  tryCatch({b<-tt[1,2]}, error=function(e){});
  tryCatch({c<-tt[2,1]}, error=function(e){});
  tryCatch({d<-tt[1,1]}, error=function(e){});
  tn<-d/(sum(tt));tp<-a/(sum(tt));fp<-b/sum(tt);fn<-c/sum(tt)
  tpr<-tp/(tp+fn);tnr=tn/(tn+fp);acc<-(tp+tn)/(tp+tn+fp+fn)
  nn=(a+b+c+d);po=(a+d)/nn;py=((a+b)/nn)*((a+c)/nn);pn=((c+d)/nn)*((b+d)/nn)
  pe=py+pn;kappa=(po-pe)/(1-pe);
  reslist0<-c(reslist0,v,round(tpr,4),round(tnr,4),round(acc,4),round(kappa,4) )
}
reslist2<-data.frame(matrix(c(reslist0),nrow=length(methods),byrow=TRUE)) %>%
  arrange(-as.numeric(X5)) %>% mutate(Scan="Multiple") %>%
  rename(Model=X1) %>% rename(TPR=X2) %>% rename(TNR=X3) %>% rename(Accuracy=X4) %>% rename(Kappa=X5)
#reslist2

# Combine all results together
reslist<-cbind(Impuation=j,rbind.data.frame(reslist1,reslist2))

tb<-kable(reslist, caption="Model Performance", booktabs=T) 
#%>%
#  kable_styling(latex_options = c("striped", "hold_position"))

cat('\n')

print(tb)

cat('\n')

i=i+1

}

```



